"""
E2E í…ŒìŠ¤íŠ¸: ì„±ëŠ¥ ê²€ì¦
ì²˜ë¦¬ëŸ‰, ì§€ì—°ì‹œê°„, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
"""

import pytest
import time
import psycopg2
from datetime import datetime


class TestPerformance:
    """ì„±ëŠ¥ ê²€ì¦ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture(scope="function")
    def postgres_connection(self):
        """PostgreSQL ì—°ê²°"""
        try:
            conn = psycopg2.connect(
                host='localhost',
                port=5432,
                user='postgres',
                password='postgres',
                database='marketing_roas'
            )
            yield conn
            conn.close()
        except psycopg2.OperationalError as e:
            pytest.skip(f"PostgreSQL not available: {e}")

    def test_query_performance(self, postgres_connection):
        """ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì •"""
        cursor = postgres_connection.cursor()
        test_cases = [
            ("COUNT(*)", "SELECT COUNT(*) FROM realtime.ad_events"),
            ("GROUP BY hour", """
                SELECT hour, COUNT(*) FROM realtime.ad_events
                GROUP BY hour LIMIT 100
            """),
            ("GROUP BY site_id", """
                SELECT site_id, COUNT(*) FROM realtime.ad_events
                GROUP BY site_id LIMIT 100
            """),
        ]

        try:
            for test_name, query in test_cases:
                start = time.time()
                cursor.execute(query)
                cursor.fetchall()
                elapsed = time.time() - start

                print(f"âœ… ì¿¼ë¦¬ '{test_name}': {elapsed*1000:.2f}ms")

                # SLA í™•ì¸ (< 1ì´ˆ)
                assert elapsed < 1.0, f"Query '{test_name}' took {elapsed:.2f}s (> 1s)"

        except psycopg2.ProgrammingError:
            print("âš ï¸ realtime.ad_events í…Œì´ë¸”ì´ ì—†ìŒ")
        finally:
            cursor.close()

    def test_throughput_measurement(self, kafka_producer, postgres_connection):
        """ì²˜ë¦¬ëŸ‰ ì¸¡ì •"""
        print("\nğŸ“Š ì²˜ë¦¬ëŸ‰ ì¸¡ì • ì‹œì‘...")

        # 1. ë©”ì‹œì§€ ë°œì†¡ ì†ë„ ì¸¡ì •
        num_messages = 100
        start_time = time.time()

        for i in range(num_messages):
            event = {
                'id': f'throughput_test_{i}',
                'click': i % 2,
                'hour': '2024122012',
                'banner_pos': '0',
                'site_id': 'perf_test',
                'site_domain': 'perf.com',
                'site_category': 'test',
                'app_id': None, 'app_domain': None, 'app_category': None,
                'device_id': 'test', 'device_ip': '127.0.0.1', 'device_model': 'test',
                'device_type': 'test', 'device_conn_type': 'test',
                'c1': 't', 'c14': 't', 'c15': 't', 'c16': 't',
                'c17': 't', 'c18': 't', 'c19': 't', 'c20': 't', 'c21': 't'
            }
            kafka_producer.send('test_ad_events_raw', value=event)

        kafka_producer.flush()
        producer_time = time.time() - start_time
        producer_throughput = num_messages / producer_time if producer_time > 0 else 0

        print(f"âœ… Kafka Producer ì²˜ë¦¬ëŸ‰: {producer_throughput:.0f} msg/sec")
        print(f"   ({num_messages} ë©”ì‹œì§€, {producer_time:.2f}ì´ˆ)")

        # 2. PostgreSQL ì¿¼ë¦¬ ì²˜ë¦¬ëŸ‰ ì¸¡ì • (5ì´ˆ ë‚´ ëª‡ ê°œ ì¿¼ë¦¬?)
        cursor = postgres_connection.cursor()
        query_count = 0
        start_time = time.time()

        try:
            while time.time() - start_time < 5:
                cursor.execute("""
                    SELECT COUNT(*) FROM realtime.ad_events LIMIT 1
                """)
                cursor.fetchone()
                query_count += 1

            query_throughput = query_count / 5
            print(f"âœ… PostgreSQL ì¿¼ë¦¬ ì²˜ë¦¬ëŸ‰: {query_throughput:.0f} queries/sec")

        except psycopg2.ProgrammingError:
            print("âš ï¸ realtime.ad_events í…Œì´ë¸”ì´ ì—†ìŒ")
        finally:
            cursor.close()

    def test_latency_distribution(self, kafka_producer, postgres_connection):
        """ì§€ì—°ì‹œê°„ ë¶„í¬ ì¸¡ì •"""
        print("\nğŸ“Š ì§€ì—°ì‹œê°„ ë¶„í¬ ì¸¡ì •...")

        latencies = []

        # 10ê°œ ë©”ì‹œì§€ë¡œ í…ŒìŠ¤íŠ¸
        for i in range(10):
            start = time.time()

            # ë©”ì‹œì§€ ë°œì†¡
            event = {
                'id': f'latency_dist_{i}_{int(start*1000)}',
                'click': i % 2,
                'hour': '2024122013',
                'banner_pos': '0',
                'site_id': 'latency',
                'site_domain': 'latency.com',
                'site_category': 'test',
                'app_id': None, 'app_domain': None, 'app_category': None,
                'device_id': 'test', 'device_ip': '127.0.0.1', 'device_model': 'test',
                'device_type': 'test', 'device_conn_type': 'test',
                'c1': 't', 'c14': 't', 'c15': 't', 'c16': 't',
                'c17': 't', 'c18': 't', 'c19': 't', 'c20': 't', 'c21': 't'
            }

            kafka_producer.send('test_ad_events_raw', value=event)
            kafka_producer.flush()

            # PostgreSQL ë„ì°© í™•ì¸ (ìµœëŒ€ 5ì´ˆ)
            cursor = postgres_connection.cursor()
            for _ in range(10):
                cursor.execute("""
                    SELECT 1 FROM realtime.ad_events
                    WHERE id = %s LIMIT 1
                """, (event['id'],))

                if cursor.fetchone():
                    latency = time.time() - start
                    latencies.append(latency)
                    break

                time.sleep(0.5)
            cursor.close()

        if latencies:
            avg_latency = sum(latencies) / len(latencies)
            min_latency = min(latencies)
            max_latency = max(latencies)

            print(f"""âœ… ì§€ì—°ì‹œê°„ ë¶„í¬:
   - ìµœì†Œ: {min_latency:.2f}ì´ˆ
   - í‰ê· : {avg_latency:.2f}ì´ˆ
   - ìµœëŒ€: {max_latency:.2f}ì´ˆ
            """)
        else:
            print("âš ï¸ ë©”ì‹œì§€ ë„ì°© ì—†ìŒ (Flink ë¯¸ì‹¤í–‰)")

    def test_table_size_growth(self, postgres_connection):
        """í…Œì´ë¸” í¬ê¸° ì¦ê°€ìœ¨ ì¸¡ì •"""
        cursor = postgres_connection.cursor()
        try:
            cursor.execute("""
                SELECT
                    schemaname,
                    tablename,
                    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
                FROM pg_tables
                WHERE schemaname IN ('realtime', 'analytics')
                ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
            """)

            results = cursor.fetchall()

            if results:
                print("\nğŸ“Š í…Œì´ë¸” í¬ê¸°:")
                total_size = 0
                for schema, table, size in results:
                    print(f"   {schema}.{table}: {size}")

                    # ìˆ«ì ì¶”ì¶œí•´ì„œ í•©ê³„ ê³„ì‚° (ì„ íƒì )
            else:
                print("âš ï¸ í…Œì´ë¸”ì´ ì—†ìŒ")

        except (psycopg2.ProgrammingError, psycopg2.OperationalError) as e:
            print(f"âš ï¸ í…Œì´ë¸” ì¡°íšŒ ì‹¤íŒ¨: {e}")
        finally:
            cursor.close()

    def test_index_usage(self, postgres_connection):
        """ì¸ë±ìŠ¤ ì‚¬ìš© í˜„í™©"""
        cursor = postgres_connection.cursor()
        try:
            cursor.execute("""
                SELECT
                    schemaname,
                    tablename,
                    indexname,
                    idx_scan as scans
                FROM pg_stat_user_indexes
                WHERE schemaname IN ('realtime', 'analytics')
                ORDER BY idx_scan DESC
                LIMIT 10
            """)

            results = cursor.fetchall()

            if results:
                print("\nğŸ“Š ì¸ë±ìŠ¤ ì‚¬ìš© í˜„í™©:")
                for schema, table, index, scans in results:
                    print(f"   {schema}.{table}.{index}: {scans} scans")
            else:
                print("âš ï¸ ì¸ë±ìŠ¤ ì •ë³´ ì—†ìŒ")

        except (psycopg2.ProgrammingError, psycopg2.OperationalError):
            print("âš ï¸ ì¸ë±ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨")
        finally:
            cursor.close()

    def test_connection_pool_health(self, postgres_connection):
        """ì—°ê²° í’€ ìƒíƒœ í™•ì¸"""
        cursor = postgres_connection.cursor()
        try:
            cursor.execute("SELECT datname, count(*) FROM pg_stat_activity GROUP BY datname")
            results = cursor.fetchall()

            print("\nğŸ“Š ì—°ê²° ìƒíƒœ:")
            for dbname, count in results:
                if dbname:
                    print(f"   {dbname}: {count} ì—°ê²°")

        except (psycopg2.ProgrammingError, psycopg2.OperationalError):
            print("âš ï¸ ì—°ê²° ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨")
        finally:
            cursor.close()
